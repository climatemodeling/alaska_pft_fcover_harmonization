{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3cc65c8-8f08-4c77-ba9c-5a437b52fee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely import wkt\n",
    "from datetime import date, timedelta\n",
    "import os\n",
    "import numpy as np\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "304ee2ac-ab5b-4a59-ab32-e40dbb8681f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=RpryWaZR19ytEWsEloDDx5jGAZ9_yfvdSd2TsGtxTqY&tc=I_ORBGB31fKc2wgOVC8lpYmrgBvg02dod0igKk3rv3Q&cc=NPtuez6PXyuZLSHaszuMc1uuaGTwnT-Se3hJla9rnUI>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=RpryWaZR19ytEWsEloDDx5jGAZ9_yfvdSd2TsGtxTqY&tc=I_ORBGB31fKc2wgOVC8lpYmrgBvg02dod0igKk3rv3Q&cc=NPtuez6PXyuZLSHaszuMc1uuaGTwnT-Se3hJla9rnUI</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter verification code:  4/1AfJohXn6SE97Zh1xYk6RlXMwPlAjzoOF02W55COSu4P2pGdoXtPeHvCUJgM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57f8a026-b6b9-4b71-bb51-6ddfb7ce0f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed84bcd5-eb24-4986-8eef-d5607ab2d317",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRIDSIZE = 18000\n",
    "BUFFER = 50\n",
    "SCALE = 10\n",
    "BANDS = ['B12', 'B8', 'B4', 'B3', 'B2', 'SCL']\n",
    "\n",
    "# cloud filter params\n",
    "CLOUD_FILTER = 90\n",
    "CLD_PRB_THRESH = 50\n",
    "NIR_DRK_THRESH = 0.15\n",
    "CLD_PRJ_DIST = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0263c6-0957-4399-af06-e54c1051c962",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958cfe38-edc5-49d2-a705-e7b37c5290cc",
   "metadata": {},
   "source": [
    "## HUC6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b839fc43-1e85-4535-9321-d6488a77010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load HUC data\n",
    "hucs = ee.List(['190604', '190603', '190602'])\n",
    "admin_fcol = (ee.FeatureCollection(\"USGS/WBD/2017/HUC06\").filter(ee.Filter.inList('huc6', hucs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41b6cb04-99cd-4ae2-97ef-e2f2c98a3283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid(region, scale):\n",
    "    \"\"\"\n",
    "    Creates a grid around a specified ROI.\n",
    "    User inputs their reasonably small ROI.\n",
    "    User inputs a scale where 100000 = 100km.\n",
    "    \"\"\"\n",
    "    # Creates image with 2 bands ('longitude', 'latitude') in degrees\n",
    "    lonLat = ee.Image.pixelLonLat()\n",
    "\n",
    "    # Select bands, multiply times big number, and truncate\n",
    "    lonGrid = (lonLat\n",
    "               .select('latitude')\n",
    "               .multiply(10000000)\n",
    "               .toInt())\n",
    "    latGrid = (lonLat\n",
    "              .select('longitude')\n",
    "              .multiply(10000000)\n",
    "              .toInt())\n",
    "\n",
    "    # Multiply lat and lon images and reduce to vectors\n",
    "    grid = (lonGrid\n",
    "            .multiply(latGrid)\n",
    "            .reduceToVectors(\n",
    "                geometry = region,\n",
    "                scale = scale, # 100km-sized boxes = 100,000\n",
    "                geometryType = 'polygon'))\n",
    "\n",
    "    return(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d22659e-a900-49b3-865f-684f93a4ad12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1392 squares created.\n",
      "18.0 km squares.\n"
     ]
    }
   ],
   "source": [
    "# Make your grid superimposed over ROI\n",
    "grid_xkm = make_grid(admin_fcol, GRIDSIZE)\n",
    "\n",
    "# Create dictionary of grid coordinates\n",
    "grid_dict = grid_xkm.getInfo()\n",
    "feats = grid_dict['features']\n",
    "\n",
    "# Create a list of several ee.Geometry.Polygons\n",
    "polys = []\n",
    "for d in feats:\n",
    "    coords = d['geometry']['coordinates']\n",
    "    poly = ee.Geometry.Polygon(coords)\n",
    "    polys.append(poly)\n",
    "\n",
    "print(\"{} squares created.\".format(len(polys)), flush=True)\n",
    "\n",
    "# Make the whole grid a feature collection for export purposes\n",
    "grid = ee.FeatureCollection(polys)\n",
    "num_km = GRIDSIZE / 1000\n",
    "print(f\"{num_km} km squares.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b3fc02-9118-4c50-bc4d-7dccd3caadf8",
   "metadata": {},
   "source": [
    "## Obs Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7fbac13-2a29-4450-bd43-7d19b533ee34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/6ru/anaconda3/envs/gee/lib/python3.11/site-packages/openpyxl/worksheet/_read_only.py:81: UserWarning: Unknown extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Releve number</th>\n",
       "      <th>Field releve number</th>\n",
       "      <th>Date (yyyymmdd)</th>\n",
       "      <th>Releve area (m2)</th>\n",
       "      <th>Releve shape</th>\n",
       "      <th>Cover abundance scale</th>\n",
       "      <th>Repeat sampled (y/n)</th>\n",
       "      <th>Collection</th>\n",
       "      <th>Collection method</th>\n",
       "      <th>Syntaxon</th>\n",
       "      <th>...</th>\n",
       "      <th>Cover rock (%)</th>\n",
       "      <th>Cover water (%)</th>\n",
       "      <th>Cover litter (%)</th>\n",
       "      <th>Cover total vegetation (%)</th>\n",
       "      <th>Mean canopy height (cm)</th>\n",
       "      <th>Mean tree layer height (m)</th>\n",
       "      <th>Mean shrub layer height (cm)</th>\n",
       "      <th>Mean herb layer height (cm)</th>\n",
       "      <th>Mean moss layer height (cm)</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>SWT-1</td>\n",
       "      <td>19890801</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>irregular</td>\n",
       "      <td>Braun/Blanquet (old)</td>\n",
       "      <td>N</td>\n",
       "      <td>Relevé</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moist Carpod, Salcha, Potfru sedge, forb tundr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>SWT-2</td>\n",
       "      <td>19890801</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>irregular</td>\n",
       "      <td>Braun/Blanquet (old)</td>\n",
       "      <td>N</td>\n",
       "      <td>Relevé</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moist Salala, Calcan, Astsib tall shrubland, T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003</td>\n",
       "      <td>SWT-3</td>\n",
       "      <td>19890802</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>irregular</td>\n",
       "      <td>Braun/Blanquet (old)</td>\n",
       "      <td>N</td>\n",
       "      <td>Relevé</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dry Betnan, Leddec, Claarb, dwarf-shrub, liche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10004</td>\n",
       "      <td>SWT-4</td>\n",
       "      <td>19890802</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>irregular</td>\n",
       "      <td>Braun/Blanquet (old)</td>\n",
       "      <td>N</td>\n",
       "      <td>Relevé</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown cyanobacteria = in orig. Nostoc commun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10005</td>\n",
       "      <td>SWT-5</td>\n",
       "      <td>19890802</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>irregular</td>\n",
       "      <td>Braun/Blanquet (old)</td>\n",
       "      <td>N</td>\n",
       "      <td>Relevé</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dry Arcalp, Hiealp, dwarf-shrub, lichen tundra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3634</th>\n",
       "      <td>30387</td>\n",
       "      <td>V-TR-R-4</td>\n",
       "      <td>19990808</td>\n",
       "      <td>15.0</td>\n",
       "      <td>irregular</td>\n",
       "      <td>Braun/Blanquet (old)</td>\n",
       "      <td>N</td>\n",
       "      <td>Relevé</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Damp fine sand along stream in floodplain. Ent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3635</th>\n",
       "      <td>30388</td>\n",
       "      <td>V-TR-S-1</td>\n",
       "      <td>19990808</td>\n",
       "      <td>1.0</td>\n",
       "      <td>irregular</td>\n",
       "      <td>Braun/Blanquet (old)</td>\n",
       "      <td>N</td>\n",
       "      <td>Relevé</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Transition between river bed and loamy terrace...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3636</th>\n",
       "      <td>30389</td>\n",
       "      <td>V-TR-S-2</td>\n",
       "      <td>19990808</td>\n",
       "      <td>1.0</td>\n",
       "      <td>irregular</td>\n",
       "      <td>Braun/Blanquet (old)</td>\n",
       "      <td>N</td>\n",
       "      <td>Relevé</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Late-lying snowbed. Entered by L. Druckenmille...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3637</th>\n",
       "      <td>30390</td>\n",
       "      <td>V-TR-W-1</td>\n",
       "      <td>19990808</td>\n",
       "      <td>25.0</td>\n",
       "      <td>irregular</td>\n",
       "      <td>Braun/Blanquet (old)</td>\n",
       "      <td>N</td>\n",
       "      <td>Relevé</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cardamine polemonioides = in orig. Cardamine p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638</th>\n",
       "      <td>30391</td>\n",
       "      <td>V-TR-W-2</td>\n",
       "      <td>19990808</td>\n",
       "      <td>25.0</td>\n",
       "      <td>irregular</td>\n",
       "      <td>Braun/Blanquet (old)</td>\n",
       "      <td>N</td>\n",
       "      <td>Relevé</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Elymus alaskanus = in orig. Elymus alaskanus s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3639 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Releve number Field releve number  Date (yyyymmdd)  Releve area (m2)  \\\n",
       "0             10001               SWT-1         19890801              -1.0   \n",
       "1             10002               SWT-2         19890801              -1.0   \n",
       "2             10003               SWT-3         19890802              -1.0   \n",
       "3             10004               SWT-4         19890802              -1.0   \n",
       "4             10005               SWT-5         19890802              -1.0   \n",
       "...             ...                 ...              ...               ...   \n",
       "3634          30387            V-TR-R-4         19990808              15.0   \n",
       "3635          30388            V-TR-S-1         19990808               1.0   \n",
       "3636          30389            V-TR-S-2         19990808               1.0   \n",
       "3637          30390            V-TR-W-1         19990808              25.0   \n",
       "3638          30391            V-TR-W-2         19990808              25.0   \n",
       "\n",
       "     Releve shape Cover abundance scale Repeat sampled (y/n) Collection  \\\n",
       "0       irregular  Braun/Blanquet (old)                    N     Relevé   \n",
       "1       irregular  Braun/Blanquet (old)                    N     Relevé   \n",
       "2       irregular  Braun/Blanquet (old)                    N     Relevé   \n",
       "3       irregular  Braun/Blanquet (old)                    N     Relevé   \n",
       "4       irregular  Braun/Blanquet (old)                    N     Relevé   \n",
       "...           ...                   ...                  ...        ...   \n",
       "3634    irregular  Braun/Blanquet (old)                    N     Relevé   \n",
       "3635    irregular  Braun/Blanquet (old)                    N     Relevé   \n",
       "3636    irregular  Braun/Blanquet (old)                    N     Relevé   \n",
       "3637    irregular  Braun/Blanquet (old)                    N     Relevé   \n",
       "3638    irregular  Braun/Blanquet (old)                    N     Relevé   \n",
       "\n",
       "     Collection method  Syntaxon  ... Cover rock (%) Cover water (%)  \\\n",
       "0                  NaN       NaN  ...            0.0             0.0   \n",
       "1                  NaN       NaN  ...            0.0             0.0   \n",
       "2                  NaN       NaN  ...            0.0             0.0   \n",
       "3                  NaN       NaN  ...            0.0           100.0   \n",
       "4                  NaN       NaN  ...            5.0             0.0   \n",
       "...                ...       ...  ...            ...             ...   \n",
       "3634               NaN       NaN  ...            0.0             0.0   \n",
       "3635               NaN       NaN  ...            5.0             0.0   \n",
       "3636               NaN       NaN  ...            0.0             0.0   \n",
       "3637               NaN       NaN  ...            0.0             0.0   \n",
       "3638               NaN       NaN  ...            0.0             0.0   \n",
       "\n",
       "     Cover litter (%)  Cover total vegetation (%) Mean canopy height (cm)  \\\n",
       "0                 NaN                         NaN                    25.0   \n",
       "1                 NaN                         NaN                   200.0   \n",
       "2                 NaN                         NaN                    10.0   \n",
       "3                 NaN                         NaN                     0.0   \n",
       "4                 NaN                         NaN                     2.0   \n",
       "...               ...                         ...                     ...   \n",
       "3634              0.0                        25.0                     NaN   \n",
       "3635             25.0                        90.0                     2.0   \n",
       "3636              2.0                         0.0                     4.0   \n",
       "3637             30.0                       100.0                    10.0   \n",
       "3638             20.0                       100.0                    10.0   \n",
       "\n",
       "     Mean tree layer height (m)  Mean shrub layer height (cm)  \\\n",
       "0                           NaN                           5.0   \n",
       "1                           NaN                          60.0   \n",
       "2                           NaN                           5.0   \n",
       "3                           NaN                           0.0   \n",
       "4                           NaN                           0.0   \n",
       "...                         ...                           ...   \n",
       "3634                        NaN                           NaN   \n",
       "3635                        NaN                           NaN   \n",
       "3636                        NaN                           NaN   \n",
       "3637                        NaN                           NaN   \n",
       "3638                        NaN                           NaN   \n",
       "\n",
       "     Mean herb layer height (cm) Mean moss layer height (cm)  \\\n",
       "0                            NaN                         NaN   \n",
       "1                            NaN                         NaN   \n",
       "2                            NaN                         NaN   \n",
       "3                            NaN                         NaN   \n",
       "4                            NaN                         NaN   \n",
       "...                          ...                         ...   \n",
       "3634                         NaN                         NaN   \n",
       "3635                         NaN                         NaN   \n",
       "3636                         NaN                         NaN   \n",
       "3637                         NaN                         NaN   \n",
       "3638                         NaN                         NaN   \n",
       "\n",
       "                                                Remarks  \n",
       "0     Moist Carpod, Salcha, Potfru sedge, forb tundr...  \n",
       "1     Moist Salala, Calcan, Astsib tall shrubland, T...  \n",
       "2     Dry Betnan, Leddec, Claarb, dwarf-shrub, liche...  \n",
       "3     Unknown cyanobacteria = in orig. Nostoc commun...  \n",
       "4     Dry Arcalp, Hiealp, dwarf-shrub, lichen tundra...  \n",
       "...                                                 ...  \n",
       "3634  Damp fine sand along stream in floodplain. Ent...  \n",
       "3635  Transition between river bed and loamy terrace...  \n",
       "3636  Late-lying snowbed. Entered by L. Druckenmille...  \n",
       "3637  Cardamine polemonioides = in orig. Cardamine p...  \n",
       "3638  Elymus alaskanus = in orig. Elymus alaskanus s...  \n",
       "\n",
       "[3639 rows x 70 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load observation points for later\n",
    "d = '/mnt/poseidon/remotesensing/arctic/data/vectors/AK-AVA_Turboveg/ak_tvexport_releves_header_data_for_vegbank_20181106_ALB.xlsx'\n",
    "obs_data = pd.read_excel(d, skiprows=[1])\n",
    "obs_data = obs_data.replace(-9, np.nan)\n",
    "obs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89e4ad29-4343-4bce-b4da-97998f26b34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field releve number len: 3639 3168\n",
      "Releve number len: 3639 3639\n"
     ]
    }
   ],
   "source": [
    "# note that there are duplicate field releve number names (but Releve number is unique)\n",
    "t = obs_data.drop_duplicates(subset=['Field releve number'])\n",
    "print('Field releve number len:', len(obs_data), len(t))\n",
    "t = obs_data.drop_duplicates(subset=['Releve number'])\n",
    "print('Releve number len:', len(obs_data), len(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adfc4d02-6c57-4575-a05b-bfe6c1db860b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude (decimal degrees)</th>\n",
       "      <th>Longitude (decimal degrees)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Releve number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>68.624900</td>\n",
       "      <td>-149.593200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>68.625311</td>\n",
       "      <td>-149.591996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>68.624417</td>\n",
       "      <td>-149.595261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>68.624690</td>\n",
       "      <td>-149.597946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10005</th>\n",
       "      <td>68.623723</td>\n",
       "      <td>-149.595704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30387</th>\n",
       "      <td>70.768889</td>\n",
       "      <td>-109.160833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30388</th>\n",
       "      <td>70.769167</td>\n",
       "      <td>-109.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30389</th>\n",
       "      <td>70.768889</td>\n",
       "      <td>-109.160833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30390</th>\n",
       "      <td>70.750000</td>\n",
       "      <td>-109.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30391</th>\n",
       "      <td>70.768889</td>\n",
       "      <td>-109.160833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3639 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Latitude (decimal degrees)  Longitude (decimal degrees)\n",
       "Releve number                                                         \n",
       "10001                           68.624900                  -149.593200\n",
       "10002                           68.625311                  -149.591996\n",
       "10003                           68.624417                  -149.595261\n",
       "10004                           68.624690                  -149.597946\n",
       "10005                           68.623723                  -149.595704\n",
       "...                                   ...                          ...\n",
       "30387                           70.768889                  -109.160833\n",
       "30388                           70.769167                  -109.062500\n",
       "30389                           70.768889                  -109.160833\n",
       "30390                           70.750000                  -109.150000\n",
       "30391                           70.768889                  -109.160833\n",
       "\n",
       "[3639 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_geom = obs_data[['Latitude (decimal degrees)', 'Longitude (decimal degrees)', 'Releve number']]\n",
    "obs_geom.set_index('Releve number', inplace=True)\n",
    "obs_geom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0adb7af-396f-4326-926a-ff8c449bae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_points = geemap.df_to_ee(obs_geom, latitude='Latitude (decimal degrees)', longitude='Longitude (decimal degrees)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05226909-7ff2-4f75-98e2-df9740c9afcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obs_points.aggregate_array('system:index').getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57dccd1a-ab29-4bdd-82ed-efb379d2749f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samplepoints = obs_points.filterBounds(polys[164])\n",
    "samplepoints.size().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5da2da10-839c-47c1-98f1-66fb21eaa22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb8b9a265d3430a8d1eeedf50edaa1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[20, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Togg…"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Map = geemap.Map()\n",
    "Map.addLayer(grid, {}, \"grid\")\n",
    "Map.addLayer(obs_points, {'color':'red'}, 'observations')\n",
    "Map.addLayer(samplepoints, {'color':'purple'}, 'observations_AK')\n",
    "Map.centerObject(samplepoints)\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc3c789-f409-4e8b-9067-b627afb37da3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee1554bf-19d3-457c-a6f0-9c8778fe6835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Vars\n",
    "year1 = 2019\n",
    "INCREMENT = 20 # timeseries composite length\n",
    "startDate = str(year1) + '-03-15'\n",
    "endDate = str(year1) + '-10-20'\n",
    "start_date = date(2019, 3, 15)\n",
    "end_date = date(2019, 10, 20)\n",
    "\n",
    "# SET VI - ndvi, evi, ndpi, gcc\n",
    "VI_index = 'ndvi' \n",
    "# Set the percentage of amplitude for the estimation of the threshold\n",
    "th = 0.5 # advice 0.2-0.8\n",
    "# Set the minimum NDVI value for the reclassification of non-vegetated\n",
    "threshMin = 0.3\n",
    "# Set scale of the analysis # between 100 to 50 optimal <50 to 10 no graph plot\n",
    "scale = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c452f98-560f-4bbd-b065-ec4c71906062",
   "metadata": {},
   "source": [
    "# Interpolation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fef2d8e5-330b-407c-805e-70f3ba802fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that interpolates phenology curve\n",
    "def cubicInterpolation(collection, step):\n",
    "\n",
    "    #listDekads = ee.List.sequence(1, collection.size().subtract(3), 1)\n",
    "    #listDekads = ee.List.sequence(1, ee.Number(len(collection)).subtract(3), 1)\n",
    "    listDekads = np.arange(1, len(collection)-3, 1).tolist()\n",
    "\n",
    "    def func1(ii):\n",
    "        \n",
    "        #ii = ee.Number(ii)\n",
    "        p0 = ee.Image(collection[ii-1])\n",
    "        p1 = ee.Image(collection[ii])\n",
    "        p2 = ee.Image(collection[ii+1])\n",
    "        p3 = ee.Image(collection[ii+2])\n",
    "        \n",
    "        # p0 = ee.Image(collection.toList(10000).get(ee.Number(ii).subtract(1)))\n",
    "        # p1 = ee.Image(collection.toList(10000).get(ii))\n",
    "        # p2 = ee.Image(collection.toList(10000).get(ee.Number(ii).add(1)))\n",
    "        # p3 = ee.Image(collection.toList(10000).get(ee.Number(ii).add(2)))\n",
    "\n",
    "        diff01 = ee.Date(p1.get('system:time_start')).difference(ee.Date(p0.get('system:time_start')), 'day')\n",
    "        diff12 = ee.Date(p2.get('system:time_start')).difference(ee.Date(p1.get('system:time_start')), 'day')\n",
    "        diff23 = ee.Date(p3.get('system:time_start')).difference(ee.Date(p2.get('system:time_start')), 'day')\n",
    "        diff01nor = diff01.divide(diff12)\n",
    "        diff12nor = diff12.divide(diff12)\n",
    "        diff23nor = diff23.divide(diff12)\n",
    "\n",
    "        f0 = p1\n",
    "        f1 = p2\n",
    "        f0p = (p2.subtract(p0)).divide(diff01nor.add(diff12nor))\n",
    "        f1p = (p3.subtract(p1)).divide(diff12nor.add(diff23nor))\n",
    "        a = (f0.multiply(2)).subtract(f1.multiply(2)).add(f0p).add(f1p)\n",
    "        b = (f0.multiply(-3)).add(f1.multiply(3)).subtract(f0p.multiply(2)).subtract(f1p)\n",
    "        c = f0p\n",
    "        d = f0\n",
    "\n",
    "        xValues = np.arange(0, ee.Number(diff12.subtract(1)).getInfo(), step).tolist()\n",
    "        # xValues = ee.List.sequence(0, diff12.subtract(1), step)\n",
    "        xDates = ee.List.sequence(p1.get('system:time_start'), p2.get('system:time_start'), 86400000)\n",
    "        \n",
    "        def func2(x): \n",
    "            im = ee.Image(ee.Number(x).divide(diff12))\n",
    "            return ((im.pow(3))\n",
    "                    .multiply(a)\n",
    "                    .add((im.pow(2)).multiply(b))\n",
    "                    .add(im.multiply(c)).add(d)\n",
    "                    .set('system:time_start', ee.Number(xDates.get(x))))\n",
    "        \n",
    "        interp_imgs = []\n",
    "        for xVal in xValues:\n",
    "            interp = func2(xVal)\n",
    "            interp_imgs.append(ee.Image(interp))\n",
    "            \n",
    "        return interp_imgs\n",
    "        \n",
    "    colInterp = []\n",
    "    for dekad in listDekads:\n",
    "        i = func1(dekad) # list of interp images\n",
    "        colInterp.append(i)\n",
    "        \n",
    "    #colInterp = ee.ImageCollection(colInterp.flatten())\n",
    "    return colInterp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b30094-d270-4be3-8dc0-a7e62261ed74",
   "metadata": {},
   "source": [
    "# Sentinel 2 SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c12bbebe-d1fa-4db0-bf49-dc69104415e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = polys[164]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aebbf36b-1275-4be2-83db-e7d905bb5c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentinel 2 cloud masking functions\n",
    "\n",
    "def get_s2_sr_cld_col(aoi, start_date, end_date):\n",
    "    # Import and filter S2 SR.\n",
    "    s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "        .filterBounds(aoi)\n",
    "        .filterDate(start_date, end_date)\n",
    "        .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', CLOUD_FILTER)))\n",
    "\n",
    "    # Import and filter s2cloudless.\n",
    "    s2_cloudless_col = (ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
    "        .filterBounds(aoi)\n",
    "        .filterDate(start_date, end_date))\n",
    "\n",
    "    # Join the filtered s2cloudless collection to the SR collection by the 'system:index' property.\n",
    "    return ee.ImageCollection(ee.Join.saveFirst('s2cloudless').apply(\n",
    "        primary = s2_sr_col,\n",
    "        secondary = s2_cloudless_col,\n",
    "        condition = ee.Filter.equals(\n",
    "            leftField = 'system:index',\n",
    "            rightField = 'system:index')\n",
    "    ))\n",
    "\n",
    "def add_cloud_bands(img):\n",
    "    # Get s2cloudless image, subset the probability band.\n",
    "    cld_prb = ee.Image(img.get('s2cloudless')).select('probability')\n",
    "\n",
    "    # Condition s2cloudless by the probability threshold value.\n",
    "    is_cloud = cld_prb.gt(CLD_PRB_THRESH).rename('clouds')\n",
    "\n",
    "    # Add the cloud probability layer and cloud mask as image bands.\n",
    "    return img.addBands(ee.Image([cld_prb, is_cloud]))\n",
    "\n",
    "\n",
    "def add_shadow_bands(img):\n",
    "    # Identify water pixels from the SCL band.\n",
    "    not_water = img.select('SCL').neq(6)\n",
    "\n",
    "    # Identify dark NIR pixels that are not water (potential cloud shadow pixels).\n",
    "    SR_BAND_SCALE = 1e4\n",
    "    dark_pixels = img.select('B8').lt(NIR_DRK_THRESH*SR_BAND_SCALE).multiply(not_water).rename('dark_pixels')\n",
    "\n",
    "    # Determine the direction to project cloud shadow from clouds (assumes UTM projection).\n",
    "    shadow_azimuth = ee.Number(90).subtract(ee.Number(img.get('MEAN_SOLAR_AZIMUTH_ANGLE')));\n",
    "\n",
    "    # Project shadows from clouds for the distance specified by the CLD_PRJ_DIST input.\n",
    "    cld_proj = (img.select('clouds').directionalDistanceTransform(shadow_azimuth, CLD_PRJ_DIST*10)\n",
    "        .reproject(**{'crs': img.select(0).projection(), 'scale': 100})\n",
    "        .select('distance')\n",
    "        .mask()\n",
    "        .rename('cloud_transform'))\n",
    "\n",
    "    # Identify the intersection of dark pixels with cloud shadow projection.\n",
    "    shadows = cld_proj.multiply(dark_pixels).rename('shadows')\n",
    "\n",
    "    # Add dark pixels, cloud projection, and identified shadows as image bands.\n",
    "    return img.addBands(ee.Image([dark_pixels, cld_proj, shadows]))\n",
    "\n",
    "\n",
    "def add_cld_shdw_mask(img):\n",
    "    # Add cloud component bands.\n",
    "    img_cloud = add_cloud_bands(img)\n",
    "\n",
    "    # Add cloud shadow component bands.\n",
    "    img_cloud_shadow = add_shadow_bands(img_cloud)\n",
    "\n",
    "    # Combine cloud and shadow mask, set cloud and shadow as value 1, else 0.\n",
    "    is_cld_shdw = img_cloud_shadow.select('clouds').add(img_cloud_shadow.select('shadows')).gt(0)\n",
    "\n",
    "    # Remove small cloud-shadow patches and dilate remaining pixels by BUFFER input.\n",
    "    # 20 m scale is for speed, and assumes clouds don't require 10 m precision.\n",
    "    is_cld_shdw = (is_cld_shdw.focalMin(2).focalMax(BUFFER*2/20)\n",
    "        .reproject(**{'crs': img.select([0]).projection(), 'scale': 20})\n",
    "        .rename('cloudmask'))\n",
    "\n",
    "    # Add the final cloud-shadow mask to the image.\n",
    "    return img_cloud_shadow.addBands(is_cld_shdw)\n",
    "\n",
    "\n",
    "def apply_cld_shdw_mask(img):\n",
    "    # Subset the cloudmask band and invert it so clouds/shadow are 0, else 1.\n",
    "    not_cld_shdw = img.select('cloudmask').Not()\n",
    "\n",
    "    # Subset reflectance bands and update their masks, return the result.\n",
    "    #return img.select('B*').updateMask(not_cld_shdw)\n",
    "    return img.updateMask(not_cld_shdw).select(BANDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f496abb-3acd-4ec8-868c-124f91c1c331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that creates NDVI bands and rescales regular bands\n",
    "def func_nfe(im):\n",
    "    \n",
    "    # Adopt SCL mask\n",
    "    SCL = im.select('SCL')\n",
    "    SCLmask = SCL.eq(1).Or(SCL.eq(4)).Or(SCL.eq(5)).Or(SCL.eq(11)); # mask for non-valid observations\n",
    "    snowMask = SCL.eq(11); # snow mask\n",
    "    \n",
    "    #RescaleBand\n",
    "    blue = im.select('B2').multiply(0.0001)\n",
    "    green = im.select('B3').multiply(0.0001)\n",
    "    red = im.select('B4').multiply(0.0001)\n",
    "    nir = im.select('B8').multiply(0.0001)\n",
    "    swir = im.select('B12').multiply(0.0001)\n",
    "\n",
    "    # Generate VIs\n",
    "    ndvi = im.normalizedDifference(['B8','B4']).rename('ndvi')\n",
    "    return (ndvi.where(ndvi.lt(threshMin), threshMin)\n",
    "            .where(snowMask, threshMin)\n",
    "            .updateMask(SCLmask)\n",
    "            .set('system:time_start', im.get('system:time_start')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d27c636a-3ecd-423a-b913-e4c560f2ba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sentinel data\n",
    "s2_sr_cld_col = get_s2_sr_cld_col(ROI, str(start_date), str(end_date))\n",
    "s2_sr = (s2_sr_cld_col.map(add_cld_shdw_mask).map(apply_cld_shdw_mask))\n",
    "\n",
    "S2 = s2_sr.select(BANDS)\n",
    "S2 = S2.map(func_nfe) # rescale and create NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfe09e56-4b8f-4714-8ad7-3e17a3b0191f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8661b438339248edb900da2a64381229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[70.25715054912598, -148.51846592347846], controls=(WidgetControl(options=['position', 'transparent…"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "t = S2.max()\n",
    "bands = 'ndvi'\n",
    "rgbViz = {'min' : 0, \n",
    "          'max' : 1, \n",
    "          'bands' : bands, \n",
    "          'palette': ['blue', 'white', 'green']}\n",
    "\n",
    "Map.centerObject(ROI, 12)\n",
    "Map.addLayer(ROI, {}, 'roi')\n",
    "Map.addLayer(t.clip(ROI), rgbViz, \"S2\")\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78ac8a2-bea5-4bc6-90cb-3fa1f1f72cb6",
   "metadata": {},
   "source": [
    "# Create time step composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "957fa514-8128-4116-8e49-8ebe381240e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = date(2019, 3, 15)\n",
    "end_date = date(2019, 10, 20)\n",
    "INCREMENT = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "641f99da-aa94-47b8-9768-4c47ea727c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_list_of_dates(start_date, end_date):\n",
    "    dates = []\n",
    "    delta = end_date - start_date   # returns timedelta\n",
    "\n",
    "    for i in range(delta.days + 1):\n",
    "        day = start_date + timedelta(days=i)\n",
    "        dates.append(day)\n",
    "    return dates\n",
    "\n",
    "def create_time_intervals(dates_list, Interval):\n",
    "    time_df = pd.DataFrame({'Date': dates_list}).astype('datetime64[ns]')\n",
    "    interval = timedelta(Interval)\n",
    "    grouped_cr = time_df.groupby(pd.Grouper(key='Date', freq=interval))\n",
    "    date_ranges = []\n",
    "    for i in grouped_cr:\n",
    "        date_ranges.append(((str(i[1].min()[0]).split(' ')[0]), (str(i[1].max()[0]).split(' ')[0])))\n",
    "    return date_ranges\n",
    "\n",
    "date_ranges = create_time_intervals(create_list_of_dates(start_date, end_date), INCREMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eded1d7c-1617-4d6a-88c1-e05e97063663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2019-03-15', '2019-04-03'),\n",
       " ('2019-04-04', '2019-04-23'),\n",
       " ('2019-04-24', '2019-05-13'),\n",
       " ('2019-05-14', '2019-06-02'),\n",
       " ('2019-06-03', '2019-06-22'),\n",
       " ('2019-06-23', '2019-07-12'),\n",
       " ('2019-07-13', '2019-08-01'),\n",
       " ('2019-08-02', '2019-08-21'),\n",
       " ('2019-08-22', '2019-09-10'),\n",
       " ('2019-09-11', '2019-09-30'),\n",
       " ('2019-10-01', '2019-10-20')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_ranges # so, 11 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30241324-4434-403f-b404-0050a45f181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create median timeseries\n",
    "def create_col(date_ranges, s2, roi):\n",
    "    \n",
    "    imgs = []\n",
    "    \n",
    "    # loop through 15-day steps\n",
    "    for RANGE in date_ranges:\n",
    "        \n",
    "        # extract sentinel imagery between start and end of step dates\n",
    "        s2_step = s2.filterDate(RANGE[0], RANGE[1]).filterBounds(roi).select(['ndvi'])\n",
    "        med_im = s2_step.reduce(ee.Reducer.median()) # changes to ndvi to ndvi_median\n",
    "        \n",
    "        # set 'empty' property to 1 if there are no images\n",
    "        med_im = med_im.set('system:time_start', ee.Date(RANGE[0]).millis()).set('empty', s2_step.size().eq(0)) #.eq Returns 1 iff the first value is equal to the second.\n",
    "        med_im = ee.Image(med_im).clip(roi)\n",
    "        \n",
    "        def mask_to_mean(im):\n",
    "\n",
    "            # Window central day \n",
    "            date_window = ee.Date(im.get('system:time_start'))\n",
    "            # Window first day \n",
    "            date_startW = date_window.advance(-INCREMENT*2, 'days')\n",
    "            # Window last day \n",
    "            date_endW = date_window.advance(INCREMENT*2, 'days')\n",
    "            # Compute mean with images before and after the central window \n",
    "            meanIm1 = s2.filterDate(date_startW, date_window.advance(1, 'days')).reduce(ee.Reducer.mean())\n",
    "            meanIm2 = s2.filterDate(date_window.advance(-1, 'days'), date_endW).reduce(ee.Reducer.mean())\n",
    "            meanIm = (meanIm1.add(meanIm2)).divide(2)\n",
    "            \n",
    "            # replace masked values with mean of previous step and next step\n",
    "            return ee.Image(im.unmask(meanIm).copyProperties(im,['system:time_start']))\n",
    "        \n",
    "        med_im = mask_to_mean(med_im)\n",
    "        imgs.append(med_im)\n",
    "        \n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a04abfe-db93-4e03-a139-68f2281f0789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return median, mean temporal gap-filled images\n",
    "img_list = create_col(date_ranges, S2, ROI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ddfdc40-5721-4fd2-b0cd-96e7db29587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter dates without images and fill them with the min thresh NDVI value \n",
    "# def fill_empty(im):\n",
    "#     return ee.Image(threshMin).rename('ndvi_median').copyProperties(im, ['system:time_start'])\n",
    "\n",
    "# filled = imagecol.filterMetadata('empty', 'equals', 1).map(fill_empty)\n",
    "# imagecol = imagecol.filterMetadata('empty', 'equals', 0).merge(filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a6d4ea2-8309-4eeb-9d45-c82d063d5174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945974511cc24ba4abf3a9cd227408d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[70.25715054912598, -148.51846592347846], controls=(WidgetControl(options=['position', 'transparent…"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize a random composite\n",
    "Map = geemap.Map()\n",
    "Map.addLayer(ROI, {}, 'roi')\n",
    "Map.centerObject(ROI, 12)\n",
    "\n",
    "for i in range(len(img_list)):\n",
    "    t = img_list[i]\n",
    "    bands = 'ndvi_median'\n",
    "    rgbViz = {'min' : -1, \n",
    "              'max' : 1, \n",
    "              'bands' : bands, \n",
    "              'palette': ['blue', 'white', 'green']}\n",
    "    Map.addLayer(t.clip(ROI), rgbViz, \"S2\")\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2ef48a83-2570-48d7-9c67-f40512cd9aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_visualize_map(img_list, index):\n",
    "    # Visualize a random composite\n",
    "    Map = geemap.Map()\n",
    "    Map.addLayer(ROI, {}, 'roi')\n",
    "    Map.centerObject(ROI, 12)\n",
    "\n",
    "    t = img_list[index]\n",
    "    bands = 'ndvi_median'\n",
    "    rgbViz = {'min' : -1, \n",
    "              'max' : 1, \n",
    "              'bands' : bands, \n",
    "              'palette': ['blue', 'white', 'green']}\n",
    "    Map.addLayer(t.clip(ROI), rgbViz, \"S2\")\n",
    "    return Map\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a3d98671-a344-4897-ac46-d5b40f79decd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc857dc9631437b9303a7750c24fd78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[70.25715054912598, -148.51846592347846], controls=(WidgetControl(options=['position', 'transparent…"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_visualize_map(img_list, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37da864e-b4dd-4752-986b-846089a938fc",
   "metadata": {},
   "source": [
    "# Manage empty composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf6ecadf-afe4-45c1-a8e1-1507d77e313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLAG PIXELS WITH NO VALID OBSERVATIONS \n",
    "# def flag_no_obs(im):\n",
    "#     return im.unmask(-999).eq(-999).copyProperties(im,['system:time_start'])\n",
    "\n",
    "# no_obs_flag = imagecol.map(flag_no_obs).filterDate(start_date, end_date).sum().eq(0).rename('flagNoObs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583a5731-41b3-4d81-883c-4ec38b8f615f",
   "metadata": {},
   "source": [
    "# Calculate phenology dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "51583faa-5449-4b36-9d91-7210882169c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate\n",
    "#interp_images = cubicInterpolation(img_list, 1) # now I have 133 images after having only 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0fb5e2e0-ed74-4892-83d5-d8a40415ef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#interp_images = list(chain.from_iterable(interp_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f714256e-926b-4918-a684-3c04b655b00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename band from 'constant' to 'ndvi_interp'\n",
    "#interp_images2 = []\n",
    "#for im in interp_images:\n",
    "#    im2 = im.rename('ndvi_interp').addBands(im.metadata('system:time_start','date1')).set('system:time_start', im.get('system:time_start'))\n",
    "#    interp_images2.append(im2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77b839d9-5796-4587-a456-11e868735716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(interp_images2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "441e343d-1c52-40cc-98d0-269a5596690d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a random composite\n",
    "# Map = geemap.Map()\n",
    "\n",
    "# t = interp_images2[5]\n",
    "# bands = 'ndvi_interp'\n",
    "# rgbViz = {'min' : -1, \n",
    "#           'max' : 1, \n",
    "#           'bands' : bands, \n",
    "#           'palette': ['blue', 'white', 'green']}\n",
    "\n",
    "# Map.centerObject(ROI)\n",
    "# Map.addLayer(ROI, {}, 'roi')\n",
    "# Map.addLayer(t.clip(ROI), rgbViz, \"S2\")\n",
    "# Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "87e16591-14ca-49cf-a2af-07217c4759d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find min, max, amplitude\n",
    "minND = ee.Image(threshMin)\n",
    "maxND = ee.ImageCollection.fromImages(img_list).max()\n",
    "amplitude = maxND.subtract(minND)\n",
    "thresh = amplitude.multiply(th).add(minND).rename('ndvi_interp')\n",
    "\n",
    "# select ndvi interp values above threshold\n",
    "# interp_images3 = []\n",
    "# for im in interp_images2:\n",
    "#     out = im.select('ndvi_interp').gt(thresh)\n",
    "#     out = im.updateMask(out)\n",
    "#     interp_images3.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "440eaa1b-e01d-4e19-8c84-a14106ebfcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get phenology information\n",
    "init = ee.Image(ee.Date(str(year1-1) + '-12-31').millis())\n",
    "\n",
    "col_aboveThresh = ee.ImageCollection.fromImages(img_list[0:1])\n",
    "SOS = col_aboveThresh.reduce(ee.Reducer.firstNonNull()).select('date1_first').rename('SOS')\n",
    "SOS_doy = SOS.subtract(init).divide(86400000)\n",
    "\n",
    "# EOS = col_aboveThresh.reduce(ee.Reducer.lastNonNull()).select('date1_last').rename('EOS')\n",
    "# EOS_doy = EOS.subtract(init).divide(86400000)\n",
    "\n",
    "# LOS = EOS_doy.subtract(SOS_doy).rename('LOS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f2206582-8e8c-444c-8620-97b66b020c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map = geemap.Map()\n",
    "# Map.centerObject(ROI, 12)\n",
    "# Map.addLayer(ROI, {}, 'roi')\n",
    "# for i in range(len(img_list)):\n",
    "#     col_aboveThresh = ee.ImageCollection.fromImages([img_list[i]])\n",
    "#     #SOS = col_aboveThresh.reduce(ee.Reducer.firstNonNull()).select('date1_first').rename('SOS')\n",
    "#     #SOS_doy = SOS.subtract(init).divide(86400000)\n",
    "#     t = ee.Image(col_aboveThresh.first())\n",
    "#     bands = 'ndvi_median'\n",
    "#     rgbViz = {'min' : -1, \n",
    "#           'max' : 1, \n",
    "#           'bands' : bands, \n",
    "#           'palette': ['blue', 'white', 'green']}\n",
    "\n",
    "#     Map.addLayer(t.clip(ROI), rgbViz, f\"S{i}\")\n",
    "# Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "54e9099d-87fd-4293-92db-0e747d2da37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # interpolate\n",
    "# interp_imagecol = cubicInterpolation(imagecol, 1) # e.g. now I have ~120 images after having only 11\n",
    "\n",
    "# init = ee.Image(ee.Date(str(year1-1) + '-12-31').millis())\n",
    "\n",
    "# def func3(im): \n",
    "#     return (im.rename('ndvi_interp')\n",
    "#             .addBands(im.metadata('system:time_start','date1'))\n",
    "#             .set('system:time_start',im.get('system:time_start')))\n",
    "# interp = interp_imagecol.map(func3)\n",
    "\n",
    "# minND = ee.Image(threshMin)\n",
    "# maxND = imagecol.max()\n",
    "# amplitude = maxND.subtract(minND)\n",
    "# thresh = amplitude.multiply(th).add(minND).rename('ndvi_interp')\n",
    "\n",
    "# def func4(im):\n",
    "#     out = im.select('ndvi_interp').gt(thresh)\n",
    "#     return im.updateMask(out)\n",
    "# col_aboveThresh = interp.map(func4)\n",
    "\n",
    "# SOS = col_aboveThresh.reduce(ee.Reducer.firstNonNull()).select('date1_first').rename('SOS')\n",
    "# SOS_doy = SOS.subtract(init).divide(86400000)\n",
    "\n",
    "# EOS = col_aboveThresh.reduce(ee.Reducer.lastNonNull()).select('date1_last').rename('EOS')\n",
    "# EOS_doy = EOS.subtract(init).divide(86400000)\n",
    "\n",
    "# LOS = EOS_doy.subtract(SOS_doy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d582b417-041a-4fd1-a492-b940979e204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map length of season, end of season, start of season\n",
    "# Map = geemap.Map()\n",
    "# Map.centerObject(ROI, 7)\n",
    "\n",
    "# # Palette info\n",
    "# phenoPalette = ['ff0000','ff8d00','fbff00','4aff00','00ffe7','01b8ff','0036ff','fb00ff']\n",
    "# visLOS = {'min': 50, 'max': 200, 'palette': phenoPalette}\n",
    "# visSOS = {'min': 20, 'max': 200, 'palette': phenoPalette}\n",
    "# visEOS = {'min': 150, 'max': 300, 'palette': phenoPalette}\n",
    "\n",
    "# # Add map layers\n",
    "# Map.addLayer(SOS.clip(ROI), visSOS, 'SOS')\n",
    "# Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "757c2a7c-5f18-4f82-9ad8-b579a086c14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample sentinel 2 imagery using our observation points\n",
    "def sample_raster(image, fcollection, scale=100, projection='EPSG:4326', geometries=False):\n",
    "    fc = image.sampleRegions(collection = fcollection,\n",
    "                             scale = scale,\n",
    "                             projection = projection,\n",
    "                             geometries = geometries)\n",
    "    return fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4e9bf06d-7706-4127-a2da-5c865dc79480",
   "metadata": {},
   "outputs": [],
   "source": [
    "samplepoints = obs_points.filterBounds(ROI)\n",
    "#los = sample_raster(LOS, samplepoints)\n",
    "#eos = sample_raster(EOS_doy, samplepoints)\n",
    "sos = sample_raster(SOS_doy, samplepoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "45f5a9d7-bcc8-45e5-b2dd-12429cd26fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_to_df(fc, idx_col):\n",
    "    # Convert a FeatureCollection into a pandas DataFrame\n",
    "    # Features is a list of dict with the output\n",
    "    features = fc.getInfo()['features']\n",
    "\n",
    "    dictarr = []\n",
    "\n",
    "    for f in features:\n",
    "        attr = f['properties']\n",
    "        dictarr.append(attr)\n",
    "\n",
    "    df = pd.DataFrame(dictarr)\n",
    "    df.set_index(idx_col, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "150fc9dc-8dca-48d9-a863-7fd48e024b64",
   "metadata": {},
   "outputs": [
    {
     "ename": "EEException",
     "evalue": "Image.select: Pattern 'date1_first' did not match any bands.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/gee/lib/python3.11/site-packages/ee/data.py:352\u001b[0m, in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 352\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_retries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mHttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/gee/lib/python3.11/site-packages/googleapiclient/_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/gee/lib/python3.11/site-packages/googleapiclient/http.py:938\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpError(resp, content, uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muri)\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostproc(resp, content)\n",
      "\u001b[0;31mHttpError\u001b[0m: <HttpError 400 when requesting https://earthengine.googleapis.com/v1/projects/earthengine-legacy/value:compute?prettyPrint=false&alt=json returned \"Image.select: Pattern 'date1_first' did not match any bands.\". Details: \"Image.select: Pattern 'date1_first' did not match any bands.\">",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEEException\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[147], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# los_df = fc_to_df(los, 'id')\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# eos_df = fc_to_df(eos, 'id')\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m sos_df \u001b[38;5;241m=\u001b[39m \u001b[43mfc_to_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43msos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[146], line 4\u001b[0m, in \u001b[0;36mfc_to_df\u001b[0;34m(fc, idx_col)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfc_to_df\u001b[39m(fc, idx_col):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Convert a FeatureCollection into a pandas DataFrame\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Features is a list of dict with the output\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[43mfc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetInfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m     dictarr \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m features:\n",
      "File \u001b[0;32m~/anaconda3/envs/gee/lib/python3.11/site-packages/ee/collection.py:141\u001b[0m, in \u001b[0;36mCollection.getInfo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetInfo\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Any]:\n\u001b[1;32m    129\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns all the known information about this collection.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m  This function makes an REST call to to retrieve all the known information\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m         properties.\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetInfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/gee/lib/python3.11/site-packages/ee/computedobject.py:103\u001b[0m, in \u001b[0;36mComputedObject.getInfo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetInfo\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Any]:\n\u001b[1;32m     98\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Fetch and return information about this object.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m  Returns:\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    The object can evaluate to anything.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomputeValue\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/gee/lib/python3.11/site-packages/ee/data.py:971\u001b[0m, in \u001b[0;36mcomputeValue\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    968\u001b[0m body \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpression\u001b[39m\u001b[38;5;124m'\u001b[39m: serializer\u001b[38;5;241m.\u001b[39mencode(obj, for_cloud_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)}\n\u001b[1;32m    969\u001b[0m _maybe_populate_workload_tag(body)\n\u001b[0;32m--> 971\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_execute_cloud_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_get_cloud_projects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_get_projects_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprettyPrint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/gee/lib/python3.11/site-packages/ee/data.py:354\u001b[0m, in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    352\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m call\u001b[38;5;241m.\u001b[39mexecute(num_retries\u001b[38;5;241m=\u001b[39mnum_retries)\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mHttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 354\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m _translate_cloud_exception(e)\n",
      "\u001b[0;31mEEException\u001b[0m: Image.select: Pattern 'date1_first' did not match any bands."
     ]
    }
   ],
   "source": [
    "# los_df = fc_to_df(los, 'id')\n",
    "# eos_df = fc_to_df(eos, 'id')\n",
    "sos_df = fc_to_df(sos, 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e68d5c2-7933-4ddb-a510-fb21ed845838",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([sos_df, eos_df, los_df], axis=1)\n",
    "df = df.loc[:,~df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233fc741-b5e1-4746-a0e1-6c2e7959d366",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['plot_size', 'year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ba689e-6e70-4715-baad-8c3687d0d30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "68bc7b02-52bf-4b33-a60b-f42623a7c432",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/mnt/poseidon/remotesensing/arctic/data/training/huc190604_pheno_dates_01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edb3cb6-f214-405c-8d4d-042d44f4d2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
