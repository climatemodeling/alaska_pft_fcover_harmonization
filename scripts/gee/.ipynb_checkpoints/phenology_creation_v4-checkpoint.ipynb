{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2089e535-a9d1-47df-82aa-028ee2a5aef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import logging\n",
    "import multiprocessing\n",
    "from retry import retry\n",
    "# https://gist.github.com/gorelick-google/cbd91d132964f39c4603b236919bceac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3d18ee5-35d0-41e7-a4f8-9421fec1cd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7869b2-b983-48ab-b21a-37761900e2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the results will be stored here so we can output a single file at the end.\n",
    "def getRequests():\n",
    "    \"\"\"Generates a list of work items to be downloaded.\n",
    "\n",
    "    Extract the ADM2_CODEs from the GAUL level 2 dataset as work units.\n",
    "    \"\"\"\n",
    "    # load observation points for later\n",
    "    d = '/mnt/poseidon/remotesensing/arctic/data/vectors/AK-AVA_Turboveg/ak_tvexport_releves_header_data_for_vegbank_20181106_ALB.xlsx'\n",
    "    obs_data = pd.read_excel(d, skiprows=[1])\n",
    "    obs_data = obs_data.replace(-9, np.nan)\n",
    "    \n",
    "    obs_geom = obs_data[['Latitude (decimal degrees)', 'Longitude (decimal degrees)', 'Releve number']]\n",
    "    obs_geom.set_index('Releve number', inplace=True)\n",
    "    obs_points = geemap.df_to_ee(obs_geom, latitude='Latitude (decimal degrees)', longitude='Longitude (decimal degrees)')\n",
    "    \n",
    "    return obs_points.aggregate_array('system:index').getInfo()\n",
    "\n",
    "@retry(tries=10, delay=1, backoff=2)\n",
    "def getResult(index, regionID):\n",
    "    \"\"\"Handle the HTTP requests to download one result.\"\"\"\n",
    "    region = (ee.FeatureCollection(\"USGS/WBD/2017/HUC06\")\n",
    "            .filter(ee.Filter.eq('huc6', regionID))\n",
    "            .first())\n",
    "\n",
    "    def maxLST(image):\n",
    "        # Mappable function to aggregate the max LST for one image.\n",
    "        # It builds an output tuple of (max_LST, date, regionID)\n",
    "        # This function uses -999 to indicate no data.\n",
    "        date = image.date().format('YYYY-MM-dd')\n",
    "        maxValue = (image.reduceRegion(ee.Reducer.median(), region.geometry())\n",
    "                    # set a default in case there's no data in the region\n",
    "                    .combine({'ndvi': -999}, False)\n",
    "                    .getNumber('ndvi')\n",
    "                    # format to 2 decimal places.\n",
    "                    .format('%.2f'))\n",
    "\n",
    "        return image.set('output', [maxValue, date, regionID])\n",
    "\n",
    "    # calculate NDVI function\n",
    "    def get_ndvi(im):\n",
    "        ndvi = (im.normalizedDifference(['B8','B4'])\n",
    "                .rename('ndvi')\n",
    "                .set('system:time_start', im.get('system:time_start'))\n",
    "        return ndvi\n",
    "\n",
    "    # Get the max LST for this region, in each image.\n",
    "    timeSeries = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "                  .select(['B8', 'B4'])\n",
    "                  .map(get_ndvi)\n",
    "                  .select('ndvi')\n",
    "                  .map(maxLST))\n",
    "                \n",
    "    result = timeSeries.aggregate_array('output').getInfo()\n",
    "\n",
    "    # Write the results to a file.\n",
    "    filename = '/mnt/poseidon/remotesensing/arctic/data/vectors/test/results_%d.csv' % regionID\n",
    "    with open(filename, 'w') as out_file:\n",
    "    for items in result:\n",
    "        line = ','.join([str(item) for item in items])\n",
    "        print(line, file=out_file)\n",
    "\n",
    "    print(\"Done: \", index)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig()\n",
    "    items = getRequests()\n",
    "\n",
    "    pool = multiprocessing.Pool(25)\n",
    "    pool.starmap(getResult, enumerate(items))\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
