{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a79376b8-4bc4-4fab-9e14-5cb81929f7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')\n",
    "\n",
    "import geemap\n",
    "import os\n",
    "import time\n",
    "from datetime import date, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mpi4py import MPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "422d91c8-5efb-4be3-85c9-c1599c57f8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# Set Parameters\n",
    "##########################################################################################\n",
    "\n",
    "# area of interest params\n",
    "# choose bounding area format ('STATE', 'COUNTRY', 'BBOX', 'HUC', 'SHP'):\n",
    "ROI = 'SHP'\n",
    "\n",
    "# if ROI = BBOX or SHP (path to .geojson or .shp, otherwise ''):\n",
    "IN_PATH = '/mnt/poseidon/remotesensing/arctic/data/vectors/supplementary/tundra_alaska/tundra_alaska.shp'\n",
    "# if ROI = STATE or COUNTRY (administrative boundaries, otherwise None):\n",
    "COUNTRY = None\n",
    "# if ROI = HUC, state abbreviation for HUC, if STATE, fulls state name:\n",
    "STATE = None # 'AK' \n",
    "# if ROI = HUC (list of HUC6 units):\n",
    "HUCLIST = None # must be list: ['190604', '190603', '190602']\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "# buffer around point to find median of intersecting pixel values\n",
    "POINTBUFFER = 30 # meters\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "# output file\n",
    "DIR_PATH = '/mnt/poseidon/remotesensing/arctic/data/rasters/S1GRD/training_test04'\n",
    "try:\n",
    "    if os.path.isdir(DIR_PATH) == False:\n",
    "        os.mkdir(DIR_PATH)\n",
    "except Exception as e:\n",
    "    pass\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "# data Information\n",
    "IDCOL = 'Site Code'\n",
    "SCALE = 10\n",
    "BANDS = ['VV', 'HH', 'VH', 'HV']\n",
    "start_date = date(2019, 6, 1)# Y-M-D (2019, 1, 1)\n",
    "end_date = date(2019, 8, 31) # Y-M-D minus 5 for even 'days' intervals (6 days for 2020)\n",
    "TIMESTEP = None # 'months', 'days', or None\n",
    "DAYS = '' # if TIMESTEP = days\n",
    "MONTHS = '' # if TIMESTEP = 'months': years * 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55828701-5753-4177-8f86-b6bb2a788f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# Create ee_to_df function for exporting\n",
    "##########################################################################################\n",
    "\n",
    "def ee_to_df(ee_object, col_names, sort_columns=False):\n",
    "    if isinstance(ee_object, ee.Feature):\n",
    "        ee_object = ee.FeatureCollection([ee_object])\n",
    "\n",
    "    if not isinstance(ee_object, ee.FeatureCollection):\n",
    "        raise TypeError(\"ee_object must be an ee.FeatureCollection\")\n",
    "\n",
    "    try:\n",
    "        property_names = ee_object.first().propertyNames().sort().getInfo()\n",
    "        #data = ee_object.map(lambda f: ee.Feature(None, f.toDictionary(property_names)))\n",
    "        data = ee_object\n",
    "        data = [x[\"properties\"] for x in data.getInfo()[\"features\"]]\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        if col_names is None:\n",
    "            col_names = property_names\n",
    "            col_names.remove(\"system:index\")\n",
    "        elif not isinstance(col_names, list):\n",
    "            raise TypeError(\"col_names must be a list\")\n",
    "\n",
    "        df = df[col_names]\n",
    "\n",
    "        if sort_columns:\n",
    "            df = df.reindex(sorted(df.columns), axis=1)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise Exception(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aa86301-ac55-4161-9ffc-17d671b8ba84",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# Set Date Ranges\n",
    "##########################################################################################\n",
    "# days\n",
    "\n",
    "if TIMESTEP == 'days':\n",
    "\n",
    "    def create_list_of_dates(start_date, end_date):\n",
    "        dates = []\n",
    "        delta = end_date - start_date   # returns timedelta\n",
    "\n",
    "        for i in range(delta.days + 1):\n",
    "            day = start_date + timedelta(days=i)\n",
    "            dates.append(day)\n",
    "        return dates\n",
    "\n",
    "    def create_time_intervals(dates_list, Interval):\n",
    "        time_df = pd.DataFrame({'Date': dates_list}).astype('datetime64[ns]')\n",
    "        interval = timedelta(Interval)\n",
    "        grouped_cr = time_df.groupby(pd.Grouper(key='Date', freq=interval))\n",
    "        date_ranges = []\n",
    "        for i in grouped_cr:\n",
    "            date_ranges.append(((str(i[1].min()[0]).split(' ')[0]), \n",
    "                                (str(i[1].max()[0]).split(' ')[0])))\n",
    "        return date_ranges\n",
    "\n",
    "    date_ranges = create_time_intervals(create_list_of_dates(start_date, \n",
    "                                                             end_date), \n",
    "                                        DAYS)\n",
    "    print(date_ranges)\n",
    "\n",
    "##########################################################################################\n",
    "# months\n",
    "\n",
    "elif TIMESTEP == 'months':\n",
    "\n",
    "    def create_list_of_dates(start_date, end_date):\n",
    "\n",
    "        dates = []\n",
    "        end_date = end_date - relativedelta(months=MONTHS-1)\n",
    "        for i in range(MONTHS):\n",
    "            delta = relativedelta(months=i)\n",
    "            month_start = start_date + delta\n",
    "            month_end = end_date + delta\n",
    "            dates.append((month_start.strftime('%Y-%m-%d'), \n",
    "                          month_end.strftime('%Y-%m-%d')))\n",
    "        return dates\n",
    "\n",
    "    date_ranges = create_list_of_dates(start_date, end_date)\n",
    "    print(date_ranges)\n",
    "\n",
    "##########################################################################################\n",
    "# no step\n",
    "\n",
    "elif TIMESTEP == None:\n",
    "\n",
    "    date_ranges = [(start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'))]\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\"Invalid TIMESTEP selection. Use 'days', 'months', or None.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d52307e-fbe5-447b-9377-7d6b020a52d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 1\n",
    "size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "312bfd95-c417-4948-96dd-03cab5202b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK: 1 HH\n"
     ]
    }
   ],
   "source": [
    "##########################################################################################\n",
    "# Set Ranks by Number of bands\n",
    "##########################################################################################\n",
    "\n",
    "# create band directories\n",
    "allbands = np.array(BANDS)\n",
    "allbands = np.array_split(allbands, size) # split array into x pieces\n",
    "for r in range(len(allbands)):\n",
    "    if r == rank:\n",
    "        CURRENTBANDS = BANDS[r] # select object from list (could be str or lst)\n",
    "        PATH = f'{DIR_PATH}/{CURRENTBANDS}'\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print('RANK:', rank, CURRENTBANDS, flush = True)\n",
    "\n",
    "# create timestamp directories within each huc (rank)\n",
    "if os.path.isdir(PATH):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39ac63be-a904-4dcb-9728-703b6acc09f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# Set GEE Vector Bounds\n",
    "##########################################################################################\n",
    "\n",
    "# Import admin data and select country to create grid around\n",
    "if ROI == 'STATE':\n",
    "    grid_location_ee = (ee.FeatureCollection(\"FAO/GAUL/2015/level1\")\n",
    "                        .filterMetadata('ADM0_NAME', 'equals', COUNTRY)\n",
    "                        .filterMetadata('ADM1_NAME', 'equals', STATE))\n",
    "\n",
    "elif ROI == 'COUNTRY':\n",
    "    grid_location_ee = (ee.FeatureCollection(\"FAO/GAUL/2015/level1\")\n",
    "                        .filterMetadata('ADM0_NAME', 'equals', COUNTRY))\n",
    "\t\n",
    "elif ROI == 'BBOX':\n",
    "\tgrid_location_ee = geemap.geojson_to_ee(IN_PATH)\n",
    "    \n",
    "elif ROI == 'HUC':\n",
    "    grid_location_ee = (ee.FeatureCollection(\"USGS/WBD/2017/HUC06\")\n",
    "                        .filter(ee.Filter.inList('huc6', HUCLIST)))\n",
    "    \n",
    "elif ROI == 'SHP':\n",
    "    geodataframe = gpd.read_file(IN_PATH)\n",
    "    grid_location_ee = geemap.geopandas_to_ee(geodataframe)\n",
    "    \n",
    "else:\n",
    "    print('Invalid region of interest. Check STATE, COUNTRY, HUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7df2799f-a779-4a89-9117-e707453c03c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185\n",
      "107\n",
      "90\n",
      "47\n",
      "86\n",
      "515\n",
      "515\n",
      "514 30-meter buffered points.\n"
     ]
    }
   ],
   "source": [
    "##########################################################################################\n",
    "# Get Sampling Points\n",
    "##########################################################################################\n",
    "\n",
    "##########################################################################################\n",
    "# AKVEG test 04\n",
    "di = '/mnt/poseidon/remotesensing/arctic/data/training/Test_05/fcover/'\n",
    "fi = 'VEG_fcover_parent.csv'\n",
    "obs_data = pd.read_csv(di + fi)\n",
    "\n",
    "# extract geometry and unique ID\n",
    "akv_geom = obs_data[['latitude', \n",
    "                     'longitude', \n",
    "                     'Site Code']]\n",
    "print(len(akv_geom))\n",
    "akv_geom.columns = ['latitude', 'longitude', 'Site Code']\n",
    "\n",
    "##########################################################################################\n",
    "# ABR_RS test 04\n",
    "di = '/mnt/poseidon/remotesensing/arctic/data/training/Test_05/fcover/'\n",
    "fi = 'ABR_fcover_parent.csv'\n",
    "obs_data = pd.read_csv(di + fi)\n",
    "\n",
    "# extract geometry and unique ID\n",
    "abr_geom = obs_data[['latitude', \n",
    "                     'longitude', \n",
    "                     'Site Code']]\n",
    "print(len(abr_geom))\n",
    "abr_geom.columns = ['latitude', 'longitude', 'Site Code']\n",
    "\n",
    "##########################################################################################\n",
    "# AKAVA test 04\n",
    "di = '/mnt/poseidon/remotesensing/arctic/data/training/Test_05/fcover/'\n",
    "fi = 'AVA_fcover_parent.csv'\n",
    "obs_data = pd.read_csv(di + fi)\n",
    "\n",
    "# extract geometry and unique ID\n",
    "ava_geom = obs_data[['latitude', \n",
    "                     'longitude', \n",
    "                     'Site Code']]\n",
    "print(len(ava_geom))\n",
    "ava_geom.columns = ['latitude', 'longitude', 'Site Code']\n",
    "\n",
    "##########################################################################################\n",
    "# NEON\n",
    "di = '/mnt/poseidon/remotesensing/arctic/data/training/Test_05/fcover/'\n",
    "fi = 'NEO_fcover_parent.csv'\n",
    "obs_data = pd.read_csv(di + fi)\n",
    "\n",
    "# extract geometry and unique ID\n",
    "neo_geom = obs_data[['latitude', \n",
    "                     'longitude', \n",
    "                     'Site Code']]\n",
    "print(len(neo_geom))\n",
    "neo_geom.columns = ['latitude', 'longitude', 'Site Code']\n",
    "\n",
    "##########################################################################################\n",
    "# Seward test 04\n",
    "di = '/mnt/poseidon/remotesensing/arctic/data/training/Test_05/fcover/'\n",
    "fi = 'SP_fcover_parent.csv'\n",
    "obs_data = pd.read_csv(di + fi)\n",
    "\n",
    "# extract geometry and unique ID\n",
    "nge_geom = obs_data[['latitude', \n",
    "                     'longitude', \n",
    "                     'Site Code']]\n",
    "print(len(nge_geom))\n",
    "nge_geom.columns = ['latitude', 'longitude', 'Site Code']\n",
    "\n",
    "##########################################################################################\n",
    "# combine\n",
    "obs_geom = pd.concat([akv_geom, abr_geom, ava_geom, neo_geom, nge_geom], \n",
    "                     axis=0, \n",
    "                     ignore_index=True)\n",
    "print(len(obs_geom))\n",
    "\n",
    "# create ee object (feature collection)\n",
    "obs_geom = obs_geom.reset_index()\n",
    "obs_points = geemap.df_to_ee(obs_geom,\n",
    "                             latitude='latitude',\n",
    "                             longitude='longitude')\n",
    "print(obs_points.size().getInfo())\n",
    "\n",
    "##########################################################################################\n",
    "#sub-select points and extract geometry\n",
    "\n",
    "# select points that intercept HUC\n",
    "samplepoints = obs_points.filterBounds(grid_location_ee)\n",
    "\n",
    "# create dictionary of grid coordinates\n",
    "points_dict = samplepoints.getInfo()\n",
    "feats = points_dict['features']\n",
    "\n",
    "# get ID column\n",
    "unique_ids = []\n",
    "for f in feats:\n",
    "    id = f['properties'][IDCOL]\n",
    "    unique_ids.append(id)\n",
    "\n",
    "# Create a list of several ee.Geometry.Polygons\n",
    "points = []\n",
    "for f in feats:\n",
    "    coords = f['geometry']['coordinates']\n",
    "    point = ee.Geometry.Point(coords)\n",
    "    # create buffer around point for later reduce regions\n",
    "    buffered = point.buffer(POINTBUFFER)\n",
    "    points.append(buffered)\n",
    "\n",
    "# Make a feature collection for export purposes\n",
    "points_ee = ee.FeatureCollection(points)\n",
    "print(f'{len(points)} {POINTBUFFER}-meter buffered points.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ec06bc94-7189-4925-ad52-1d64b3f17868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d489f3170b84c949bb4ec831def4a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[47.3277, 5.2013], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(chil…"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mask_edge(image):\n",
    "    edge = image.lt(-30.0)\n",
    "    masked_image = image.mask().And(edge.Not())\n",
    "    return image.updateMask(masked_image)\n",
    "\n",
    "\n",
    "img_vv = (\n",
    "    ee.ImageCollection('COPERNICUS/S1_GRD')\n",
    "    .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\n",
    "    .filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
    "    .select('VV')\n",
    "    .map(mask_edge)\n",
    ")\n",
    "\n",
    "desc = img_vv.filter(ee.Filter.eq('orbitProperties_pass', 'DESCENDING'))\n",
    "asc = img_vv.filter(ee.Filter.eq('orbitProperties_pass', 'ASCENDING'))\n",
    "\n",
    "spring = ee.Filter.date('2015-03-01', '2015-04-20')\n",
    "late_spring = ee.Filter.date('2015-04-21', '2015-06-10')\n",
    "summer = ee.Filter.date('2015-06-11', '2015-08-31')\n",
    "\n",
    "desc_change = ee.Image.cat(\n",
    "    desc.filter(spring).mean(),\n",
    "    desc.filter(late_spring).mean(),\n",
    "    desc.filter(summer).mean(),\n",
    ")\n",
    "\n",
    "asc_change = ee.Image.cat(\n",
    "    asc.filter(spring).mean(),\n",
    "    asc.filter(late_spring).mean(),\n",
    "    asc.filter(summer).mean(),\n",
    ")\n",
    "\n",
    "m = geemap.Map()\n",
    "m.set_center(5.2013, 47.3277, 12)\n",
    "m.addLayer(asc_change, {'min': -25, 'max': 5}, 'Multi-T Mean ASC', True)\n",
    "m.addLayer(desc_change, {'min': -25, 'max': 5}, 'Multi-T Mean DESC', True)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f716d492-e4fe-42ab-a231-60564831c476",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57637daf2f2408d99591987fe462ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[69.29617727681926, -157.39159744032227], controls=(WidgetControl(options=['position', 'transparent…"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = '2019-06-01'\n",
    "end = '2019-08-31'\n",
    "\n",
    "col = (ee.ImageCollection('COPERNICUS/S1_GRD')\n",
    "       .filterBounds(samplepoints)\n",
    "       .filterMetadata('instrumentMode', 'equals', 'IW')\n",
    "       .filterDate(start, end)\n",
    "       .map(mask_edge))\n",
    "\n",
    "m = geemap.Map()\n",
    "m.center_object(samplepoints, zoom=8)\n",
    "m.addLayer(col.first().select('VV'), {'min': -25, 'max': 5}, 'VV', False)\n",
    "m.addLayer(col.first().select('VH'), {'min': -25, 'max': 5}, 'VH', False)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "671e19ab-c22b-4ea1-96c3-162c703ad922",
   "metadata": {},
   "outputs": [],
   "source": [
    "passdirection = col.aggregate_array('orbitProperties_pass').getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1371a210-d69f-49a1-8a6c-4c11066d53b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n"
     ]
    }
   ],
   "source": [
    "print(len([d for d in passdirection if d == 'DESCENDING']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aaef3870-e9b9-4aff-94af-f1ab24a2e5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print(len([d for d in passdirection if d == 'ASCENDING']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "51d8925a-f4d1-4e32-987d-16fb84691811",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = (col.filterMetadata('orbitProperties_pass', \n",
    "                          'equals',\n",
    "                          'DESCENDING'))\n",
    "# could normalize instead of selecting one ascending/descending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f7269258-32cb-4961-b318-e5cc2636cae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "recent = col.median()\n",
    "proportion = (recent.select('VV')\n",
    "              .subtract(recent.select('VH')).rename('proportion'))\n",
    "recent = recent.addBands(proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "396cbbb2-faef-4a21-8b93-c1e7d8ea9d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB is VV, VH, VV-VH\n",
    "rgb = ee.Image.rgb(recent.select('VV'),\n",
    "                   recent.select('VH'),\n",
    "                   recent.select('VV').subtract(recent.select('VH')))\n",
    "m.addLayer(rgb, {'min':[-18, -25, 1],\n",
    "                 'max':[0, -10, 0.5]},\n",
    "           'RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d732c0e6-2fb8-49d6-b159-aca00032122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# monitoring forest change over varying topography can create extra noise\n",
    "# apply terrain correction\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
