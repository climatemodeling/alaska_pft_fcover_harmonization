{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6a653972-658e-4613-aa24-fd5d6303244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from pyogrio import read_dataframe\n",
    "from datetime import date, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import ee\n",
    "import geemap as gee\n",
    "import time\n",
    "import standardize_pft_funcs as spf\n",
    "import math\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "be2c4825-e37b-4a09-9ef7-2b67b6226653",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ee.Initialize()\n",
    "except Exception as e:\n",
    "    print('GEE token expired. Use Jupyter Lab to authenticate')\n",
    "    ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "edfffeae-9f1b-4173-b1b2-b631480b9c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "base = '/mnt/poseidon/remotesensing/arctic/data/'\n",
    "out_path = f'{base}/training/Test_06/fcover/temp'\n",
    "data_path = f'{base}/vectors/abr/original_data'\n",
    "temp_path = f'{base}/vectors/abr/standardization_temp'\n",
    "stand_path = f'{base}/vectors/abr/standardization_info'\n",
    "harm_path = f'{base}/vectors/abr/harmonized_data'\n",
    "checklist_path = '/mnt/poseidon/remotesensing/arctic/data/vectors/akveg/AKVEG_species_checklist.csv'\n",
    "leaf_path = '/mnt/poseidon/remotesensing/arctic/data/vectors/ava_post2000/evergreendecid_macander2022.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d08859-b2d7-48e6-b5e3-2cdd13001575",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# 1. Data Preparation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738bc49d-ce3e-4498-8249-edd85633da69",
   "metadata": {},
   "source": [
    "## 1.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fc0c373f-d848-49bc-b2ae-db7f979730ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of plot-species rows: 15866\n"
     ]
    }
   ],
   "source": [
    "# read vegetation fcover as dataframe\n",
    "file = f'{data_path}/vpi_plot_species_cover_with_trace.csv'\n",
    "rs_veg_df = pd.read_csv(file)\n",
    "print(f'Number of plot-species rows: {len(rs_veg_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0ab7d133-b087-4df2-b4b2-c1708fad7798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of plots: 107\n"
     ]
    }
   ],
   "source": [
    "# read non-vegetation fcover as dataframe\n",
    "file = f'{data_path}/vpi_plot_summary.csv'\n",
    "rs_nonveg_df = pd.read_csv(file)\n",
    "nonveg_top = rs_nonveg_df[['plot_id', 'litter_topcov', 'water_topcov', 'bareground_topcov']]\n",
    "print(f'Number of plots: {len(nonveg_top)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d457396b-3bee-4664-a8bc-7078ca4e7864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-vegetation table columns: ['plot_id', 'litter_topcov', 'water_topcov', 'bareground_topcov']\n",
      "Vegetation table columns: ['plot_id', 'veg_taxonomy', 'family', 'species_cover', 'vascular', 'plot_sw_digit']\n"
     ]
    }
   ],
   "source": [
    "# get ancillary data (lat,lon,etc)\n",
    "file = f'{data_path}/plot.csv'\n",
    "ancillary = pd.read_csv(file, index_col=0)\n",
    "print(f'Non-vegetation table columns: {nonveg_top.columns.tolist()}')\n",
    "print(f'Vegetation table columns: {rs.columns.tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5f569efb-dbbf-4f3e-82fd-cd10d9c7f493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop els plots (plots that start with a letter)\n",
    "# els crew used handheld remote sensing devices,\n",
    "# which is not the data we want\n",
    "startswith_digit = [x.isdigit() for x in rs_veg_df['plot_id'].str[0]]\n",
    "rs_veg_df['plot_sw_digit'] = startswith_digit\n",
    "rs_veg_df = rs_veg_df[rs_veg_df['plot_sw_digit'] == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87add12-b991-424c-8625-f9fddf58a21d",
   "metadata": {},
   "source": [
    "## 1.2 Extract species information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "14431366-6285-4ae6-9f3a-85847fc0ad76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved unique species list to /mnt/poseidon/remotesensing/arctic/data//vectors/abr/standardization_info/abr_rs_unique_species.csv.\n"
     ]
    }
   ],
   "source": [
    "# create table of unique species\n",
    "unique_species_df = spf.get_unique_species(DFRAME=rs_veg_df, \n",
    "                                           SCOL='veg_taxonomy', \n",
    "                                           DNAME='abr_rs', \n",
    "                                           SAVE=True, \n",
    "                                           OUTP=stand_path)\n",
    "\n",
    "# load species checklist\n",
    "checklist_df = read_dataframe(checklist_path)\n",
    "\n",
    "# get first 2 words (genus-species) from checklist accepted name and data species name\n",
    "checklist_df['Mapping Name'] = checklist_df['Accepted Name'].apply(spf.get_substrings)\n",
    "unique_species_df['Mapping Name'] = unique_species_df['veg_taxonomy'].apply(spf.get_substrings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01d344b-5847-4fc9-ac53-32449a82babf",
   "metadata": {},
   "source": [
    "## 1.3 Assign species habits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "30cb61c0-3e10-4b78-b6ef-58decf3439cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161 species are missing habits.\n",
      "93 species still missing habits.\n",
      "27 species still missing habits.\n",
      "25 species still missing habits.\n"
     ]
    }
   ],
   "source": [
    "# get potential habits\n",
    "habits_df = spf.fill_habits(unique_species=unique_species_df, \n",
    "                            checklist=checklist_df, \n",
    "                            u_name='veg_taxonomy', \n",
    "                            c_unofficial_name='Name', \n",
    "                            c_official_name='Accepted Name', \n",
    "                            mapping_name='Mapping Name',\n",
    "                            habit='Habit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d3f401-ad76-4526-825c-433ab9081d14",
   "metadata": {},
   "source": [
    "## 1.4 Add leaf retention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b0e67ee3-c7a6-4d78-9b1a-652d010e9fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of current potential habits:\n",
      "['forb', 'graminoid', 'lichen', 'shrub', 'liverwort', 'dwarf shrub', 'forb, dwarf shrub, forb, shrub', 'moss', nan, 'spore-bearing', ' shrub,dwarf shrub']\n"
     ]
    }
   ],
   "source": [
    "# add leaf retention (lr) columns\n",
    "leaf_retention_df = pd.read_csv(leaf_path, header=None)\n",
    "leaf_retention_df.columns = ['evergreendecid', 'species']\n",
    "habits_df_with_lr = spf.add_leaf_habit(habits_df, leaf_retention_df)\n",
    "\n",
    "# export\n",
    "habits_df_with_lr.to_csv(f'{temp_path}/abr_species_habit_00.csv')\n",
    "\n",
    "# habits---some species can have many growth forms and\n",
    "# thus the string contains a list of habits\n",
    "habit_list = list(habits_df_with_lr['Potential Habit'].unique())\n",
    "print(f'List of current potential habits:\\n{habit_list}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0fcca8-bd07-45e6-ac53-9ad0ee955454",
   "metadata": {},
   "source": [
    "## 1.5 Export shrubs, nonshrubs, null habit seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "356fea11-da0c-4dae-9449-1f6d04099cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all non-null habit names\n",
    "nonnull_habit_df = habits_df_with_lr[~habits_df_with_lr['Potential Habit'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "58d6a6de-962f-479d-baf5-ac6e041e1b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all shrub species\n",
    "shrubs_df = nonnull_habit_df[nonnull_habit_df['Potential Habit'].str.contains('shrub')]\n",
    "shrubs_df.to_csv(f'{temp_path}/abr_shrubs_00.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d7d46231-e8c7-40c2-87ad-4464ddf29a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all non-shrub species\n",
    "nonshrubs_df = nonnull_habit_df[~nonnull_habit_df['Potential Habit'].str.contains('shrub')]\n",
    "nonshrubs_df.to_csv(f'{temp_path}/abr_nonshrubs_00.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6e5bf2cf-c884-4908-90cd-a98b42458fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get null habits\n",
    "null_habit_df = habits_df_with_lr[habits_df_with_lr['Potential Habit'].isnull()]\n",
    "null_habit_df.to_csv(f'{temp_path}/abr_nullhabit_00.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "09d35d47-4247-44d3-85f6-1bb97be4ee51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows before separating:  385\n"
     ]
    }
   ],
   "source": [
    "print('Total number of rows before separating: ', \n",
    "      len(habits_df_with_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "130947ce-5d15-4480-8b80-2b99b7f1f27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separate null habit, nonshrub habit, shrub habit row sum:  385\n"
     ]
    }
   ],
   "source": [
    "print('Separate null habit, nonshrub habit, shrub habit row sum: ', \n",
    "      (len(null_habit_df) + len(nonshrubs_df) + len(shrubs_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fe8168-51e8-49da-be75-9bc8d0f1b4ec",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# 2. Manual Cleaning\n",
    "- Manually fix habits from `shrubs_00` and `nullhabit_00`\n",
    "    - Consulted with arctic ecologist for shrubs\n",
    "    - Used web search results for null habits\n",
    "- Rename cleaned files by suffixing with `_01`\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75c6735-32b7-4eaa-8c88-1877d4c46d18",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# 3. Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77a3844-e474-4ecd-8065-31638394c8dd",
   "metadata": {},
   "source": [
    "#### PFT Schema\n",
    "---\n",
    "- veg: lichen = algae, lichen\n",
    "- veg: bryophyte = liverwort, moss\n",
    "- veg: graminoid = graminoid\n",
    "- veg: forb = spore-bearing, forb\n",
    "- veg: evergreen shrub = evergreen shrubs of all heights\n",
    "- veg: deciduous shrub = deciduous shrubs of all heights\n",
    "---\n",
    "- nonveg: litter = litter + scat\n",
    "- nonveg: bare ground = bare mineral + crust + bare ground\n",
    "- nonveg: water = water\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f96ceebe-907e-4eee-98d4-1b33381b1119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get manually adjusted data\n",
    "nonshrub_path = f'{temp_path}/abr_rs_nonshrubs_00.csv'\n",
    "nullhabit_path = f'{temp_path}/abr_rs_nullhabit_01.csv'\n",
    "shrub_path = f'{temp_path}/abr_rs_shrubs_01.csv'\n",
    "\n",
    "alltypes = [nonshrub_path, shrub_path, nullhabit_path]\n",
    "\n",
    "dfs = []\n",
    "for path in alltypes:\n",
    "    habit_df = pd.read_csv(path, index_col=0)\n",
    "    dfs.append(habit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "60ecc686-62ac-49c1-8abc-8a885004a07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['forb',\n",
       " 'graminoid',\n",
       " 'lichen',\n",
       " 'liverwort',\n",
       " 'moss',\n",
       " 'spore-bearing',\n",
       " 'shrub',\n",
       " 'dwarf shrub',\n",
       " 'shrub, tree',\n",
       " 'bare ground',\n",
       " 'bare mineral',\n",
       " 'crust',\n",
       " 'litter',\n",
       " 'scat',\n",
       " 'algae',\n",
       " 'fungus',\n",
       " 'water']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show all habits after habit names have been adjusted manually\n",
    "clean_habits_df = pd.concat(dfs)\n",
    "clean_habits_df['Habit'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0948efd3-d77d-4b31-bcda-78f497ead0bf",
   "metadata": {},
   "source": [
    "## 3.1 Standardize habit (PFT) names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "09704894-e469-4162-9f82-7515c797507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition that aggregates habits into parent habits\n",
    "# this is abr-specific, which is why it's not in the SPF module\n",
    "def standardize_habit(habits, leaftypes, heights):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description\n",
    "    -----------\n",
    "    Reads habit names and assigns a standardized name. E.g. Habits\n",
    "    called 'moss' or 'liverwort' will be standardized to 'bryophyte'.\n",
    "    Column names will have the suffix 'cover (%)'\n",
    "    \n",
    "    Paramters\n",
    "    -----------\n",
    "    habits     : [pandas column] dataframe selection \n",
    "                 with orignal habit names\n",
    "    leaftypes  : [pandas column] dataframe selection \n",
    "                 with leaf retention type\n",
    "    heights    : [pandas column] dataframe selection\n",
    "                 with potential height information\n",
    "    \n",
    "    Returns\n",
    "    -----------\n",
    "    List of new habit names associated with each original habit name\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    habits = habits.to_numpy()\n",
    "    leaftypes = leaftypes.to_numpy()\n",
    "    heights = heights.to_numpy()\n",
    "    new_habits = []\n",
    "    \n",
    "    for habit, leaf, height in zip(habits, leaftypes, heights):\n",
    "        habit = habit.lower()\n",
    "        if 'algae' in habit:\n",
    "            new_habit = 'lichen cover (%)'\n",
    "        elif habit == np.nan or 'unknown' in habit:\n",
    "            new_habit = 'unknown cover (%)'\n",
    "        elif 'moss' in habit or 'liverwort' in habit:\n",
    "            new_habit = 'bryophyte cover (%)'\n",
    "        elif 'spore-bearing' in habit:\n",
    "            new_habit = 'forb cover (%)'\n",
    "        elif habit == 'grass':\n",
    "            new_habit = 'graminoid cover (%)'\n",
    "            \n",
    "        elif habit == 'shrub, tree':\n",
    "            new_habit = f'{leaf} dwarf to tree cover (%)'\n",
    "        elif habit == 'dwarf shrub':\n",
    "            new_habit = f'{leaf} {habit} cover (%)'\n",
    "        elif 'shrub' in habit:\n",
    "            new_habit = f'{leaf} {height} cover (%)'\n",
    "            \n",
    "        elif 'litter' in habit or 'scat' in habit:\n",
    "            new_habit = 'litter cover (%)'\n",
    "        elif 'bare ground' in habit or 'crust' in habit or 'mineral' in habit:\n",
    "            new_habit = 'bare ground cover (%)'\n",
    "        else:\n",
    "            new_habit = f'{habit} cover (%)'\n",
    "        new_habits.append(\" \".join(new_habit.split()).lower())\n",
    "    \n",
    "    return new_habits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "43dfdb87-c30e-4a2c-81c0-2002be1924a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize habit names\n",
    "standard_habit_cols_list = standardize_habit(clean_habits_df['Habit'], \n",
    "                                             clean_habits_df['Leaf Retention'], \n",
    "                                             clean_habits_df['Height'])\n",
    "\n",
    "# add standardized habit names as column\n",
    "clean_habits_df['Standard Habit'] = standard_habit_cols_list\n",
    "\n",
    "# export\n",
    "file = f'{stand_path}/abr_rs_species_habit_standardized.csv'\n",
    "clean_habits_df.to_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa77dd79-694d-49b7-a7b4-a25a551ef2c9",
   "metadata": {},
   "source": [
    "## 3.2 Join PFT (habit) to fcover data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ea16c99e-4fbc-4c89-a0fd-a6d02986d516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add vegetation fcover and sum to PFT level\n",
    "# this is abr-specific, which is why it's not in the SPF module\n",
    "def add_cover(cover_df, pft_groups, habit_col):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description\n",
    "    -----------\n",
    "    Joins standardized PFT names with fcover data via species name.\n",
    "    For every plot, aggregate habits by summing fcover values.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    cover_df   : [pandas dataframe] dataframe with species rowwise \n",
    "                 and plots columnwise\n",
    "    pft_groups : [pandas dataframe] dataframe with species rowwise and\n",
    "                 a standard PFTs column\n",
    "    habit_col  : [string] name of column in pft_groups that have \n",
    "                 standardized PFT names\n",
    "    \n",
    "    Returns\n",
    "    -----------\n",
    "    Multi-index pandas dataframe with plots (idx0) and associated habit fcovers (idx1)\n",
    "    \"\"\"\n",
    "    \n",
    "    cover = cover_df.reset_index()\n",
    "    withfcover = cover.merge(pft_groups, \n",
    "                             left_on='veg_taxonomy', \n",
    "                             right_on='Name', \n",
    "                             how='left')\n",
    "    grouped = withfcover.groupby(['plot_id', habit_col], \n",
    "                                 group_keys=True).agg({'species_cover': 'sum'})\n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a4d225ff-70d7-4963-9655-1ea6a0308899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create standardized table layout\n",
    "grouped_standard = add_cover(rs_veg_df, clean_habits_df, 'Standard Habit')\n",
    "grouped_standard = spf.flatten_multilevel(grouped_standard)\n",
    "grouped_standard = spf.transpose_df(grouped_standard, 'Standard Habit')\n",
    "standard_groups = spf.add_standard_cols(grouped_standard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09860c31-0d8b-4fce-b2f0-49ebc22371e5",
   "metadata": {},
   "source": [
    "## 3.3 Read ancillary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1adcf22a-a324-414e-a4bb-e5470a12a2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ancillary rows:  913\n"
     ]
    }
   ],
   "source": [
    "# add ancillary information\n",
    "anc_df = ancillary.copy()\n",
    "anc_df.rename(columns={'plot_id':'Site Code'}, inplace=True)\n",
    "# year\n",
    "anc_df['year'] = pd.DatetimeIndex(anc_df['field_start_ts']).year\n",
    "anc_df['year'] = anc_df['year'].astype('Int64')\n",
    "# plot size -- ABR is all 55m\n",
    "anc_df['plot_radius_m'] = '55'\n",
    "# dataset source\n",
    "anc_df['source'] = 'ABR_RS'\n",
    "# subselect ancillary columns of interest\n",
    "anc_df = anc_df[['Site Code', 'latitude', 'longitude', 'year', 'plot_radius_m', 'source']]\n",
    "# print number of rows\n",
    "print('Number of ancillary rows: ', len(anc_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbbcff5-9a55-4f23-b2da-b153c4fea3c5",
   "metadata": {},
   "source": [
    "## 3.4 Create top cover table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "598bfbdc-2ae3-4e10-9af1-e920879fef5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns and set index\n",
    "topcover = nonveg_top.copy()\n",
    "topcover.rename(columns={'litter_topcov':'litter total cover (%)',\n",
    "                         'water_topcov':'water top cover (%)',\n",
    "                         'bareground_topcov':'bare ground top cover (%)',\n",
    "                         'plot_id':'Site Code'}, inplace=True)\n",
    "topcover1 = topcover.drop(columns=['litter total cover (%)'])\n",
    "topcover1.set_index('Site Code', inplace=True)\n",
    "topcover1 = topcover1[sorted(topcover1.columns.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a675aa46-88b4-4856-b999-e122db872b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add ancillary\n",
    "topcover1 = topcover1.merge(anc_df, on='Site Code', how='left')\n",
    "topcover1.set_index('Site Code', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "82e64529-8af6-49d2-9501-ccad28005608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional export\n",
    "file = f'{harm_path}/abr_rs_fcover_top_standardized.csv'\n",
    "topcover1.to_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "cce1d8b1-2fd2-4d09-a40f-1736db4ae2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of top cover rows:  107\n"
     ]
    }
   ],
   "source": [
    "print('Number of top cover rows: ', len(topcover1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e381a6-c3b8-47a3-b6a1-b42af89979ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3.5 Create total cover file (aggregated habits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "495194e0-c148-432f-a589-e36fc2d8bd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set index and sort columns\n",
    "totcover = standard_groups.copy()\n",
    "totcover.rename(columns={'plot_id':'Site Code'}, inplace=True)\n",
    "totcover.drop(columns=['fungus cover (%)'], inplace=True)\n",
    "totcover.set_index('Site Code', inplace=True)\n",
    "totcover.columns.name = None\n",
    "\n",
    "# add litter\n",
    "litter = topcover[['litter total cover (%)']]\n",
    "litter2 = litter.copy()\n",
    "litter2 = litter2.rename(columns={'litter total cover (%)':'litter cover (%)'}, inplace=True)\n",
    "totcover = pd.concat([totcover, litter2], axis=1)\n",
    "totcover = totcover[sorted(totcover.columns.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "69d74ed0-34c9-4bd5-a2a2-82bc2f605a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add \"total cover\" to column names\n",
    "cols = totcover.columns.tolist()\n",
    "cols = [x.replace('cover (%)' , 'total cover (%)') for x in cols]\n",
    "totcover.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e4f2d65e-4896-4758-9f2e-e04c35388870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add ancillary\n",
    "totcover = totcover.merge(anc_df, on='Site Code', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c6fb6f71-4aa4-43e9-bc7a-421e02619638",
   "metadata": {},
   "outputs": [],
   "source": [
    "totcover.set_index('Site Code', inplace=True)\n",
    "totcover.drop(columns=['water total cover (%)', 'bare ground total cover (%)'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "57ded80c-3c47-4a15-8e5c-da6924d49036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total cover rows:  107\n"
     ]
    }
   ],
   "source": [
    "print('Number of total cover rows: ', len(totcover))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "24b22107-dd56-4d7f-ae94-f49d1d4cb638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "file = f'{harm_path}/abr_rs_fcover_total_standardized.csv'\n",
    "totcover.to_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ba2ab4-0886-4e40-bbc8-aa04140fd440",
   "metadata": {},
   "source": [
    "## 3.7 Creat combined top and total cover file (aggregated habits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "dc86f3e3-77da-4a9d-a1f3-4a81e66ab6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "topcover.set_index('Site Code', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5cc79ef7-c6d6-432b-bc30-192c852faed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "allcols = pd.concat([totcover, topcover], axis=1)\n",
    "cover = sorted([col for col in allcols.columns if 'cover (%)' in col])\n",
    "other = sorted([col for col in allcols.columns if 'cover (%)' not in col])\n",
    "c = allcols[cover]\n",
    "o = allcols[other]\n",
    "allcols_final = pd.concat([c, o], axis=1)\n",
    "allcols_final = allcols_final.loc[:,~allcols_final.columns.duplicated()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7ff47264-0d29-4a2b-9115-f3cd0101de97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/poseidon/remotesensing/arctic/scripts/plot_harmonization/standardize_pft_funcs.py:346: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  e_shrub['evergreen shrub total cover (%)'] = e_shrub.sum(axis=1)\n",
      "/mnt/poseidon/remotesensing/arctic/scripts/plot_harmonization/standardize_pft_funcs.py:348: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d_shrub['deciduous shrub total cover (%)'] = d_shrub.sum(axis=1)\n",
      "/mnt/poseidon/remotesensing/arctic/scripts/plot_harmonization/standardize_pft_funcs.py:351: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  e_tree['evergreen tree total cover (%)'] = e_tree.sum(axis=1)\n",
      "/mnt/poseidon/remotesensing/arctic/scripts/plot_harmonization/standardize_pft_funcs.py:353: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d_tree['deciduous tree total cover (%)'] = d_tree.sum(axis=1)\n"
     ]
    }
   ],
   "source": [
    "# ABR plots are not near each other, so they are not\n",
    "# spatially aggregated. Regardless, I created a \"parent\"\n",
    "# and \"child\" file for consistency with plots that DO spatially\n",
    "# aggregate (aka, are within 55m of each other)\n",
    "aggregated_PFT_fcover = spf.agg_to_pft_schema(allcols_final)\n",
    "p = 'abr_fcover_parent.csv'\n",
    "c = 'abr_fcover_child.csv'\n",
    "aggregated_PFT_fcover.to_csv(f'{harm_path}/{p}')\n",
    "aggregated_PFT_fcover.to_csv(f'{harm_path}/{c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3414a7-ded7-481d-af2c-59aed0cc74cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
